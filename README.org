** Install and use

*Download workflow and dependencies, and setup databases*

#+begin_src sh
git clone https://github.com/thackl/detectEVE
cd detectEVE

# install with conda - I prefer mamba via https://github.com/conda-forge/miniforge
mamba create -n detectEVE
mamba activate detectEVE
mamba env update --file workflow/envs/env.yaml

# download and prepare rvdb and uniref50
./detectEVE --setup-databases
#+end_src

See [[Advanced database setup]] for alternatives and customization of databases.

*Analyse genomes*
#+begin_src sh
# from files
./detectEVE *.fasta

# from NCBI SRA WGS accessions
./detectEVE -a ACC [ACC ...]
#+end_src

- for *accessions*: The genome fasta files of all SRA WGS accessions will
  automatically be downloaded from NCBI to =genomes/<accession>.fna= (see
  https://www.ncbi.nlm.nih.gov/Traces/wgs/, for example, QMGA01 for the
  bottlenose dolphin).

*NOTE:* If you encounter an error related to
/tidyverse/stringi/libicui18n.so.58/, try reinstalling =stringi= locally

#+begin_src sh
mamba remove r-stringi r-tidyverse
R -e 'install.packages("stringi")'
mamba install r-tidyverse
#+end_src

To restart the workflow from where it failed, just run the same command again.

** Output
The pipeline produces the following final files in =results/=:
- =<genome_id>-validatEVEs.tsv= - best hit of the EVE with evidence and confidence
  annotation (exogenous virus: high, eve-ish description & hypothetical protein:
  low)
- =<genome_id>-validatEVEs.fna= - validatEVEs nucleotide sequences
- =<genome_id>-validatEVEs.pdf= - graphical overview of hit distribution for validatEVEs

[[file:workflow/detectEVE-output-example.png]]

** Workflow overview
[[file:workflow/detectEVE-workflow.png]]

** Advanced database setup

If you need *databases in a different location* you can adjust =db_dir= in
=config.yaml= to whatever suits your system.

If you prefer to *handle downloads manually or use existing files*, you can copy
any file you don't want to download automatically into the =databases/=
subfolder (or whatever =config.yaml/db_dir= you specified) before running
=--setup-databases=. Note though, all but the final diamond-formatted database
files will be deleted from =databases/= at the end of the setup phase.

#+begin_src sh
cd databases/

# Latest RVDB
url=https://rvdb-prot.pasteur.fr/ && 
db=$(curl -fs $url | grep -oPm1 'files/U-RVDBv[0-9.]+-prot.fasta.xz')
curl $url/$db -o rvdb100.faa.xz

# UniRef50
wget https://ftp.uniprot.org/pub/databases/uniprot/uniref/uniref50/uniref50.fasta.gz

# NCBI taxonomy stuff
wget https://ftp.ncbi.nlm.nih.gov/pub/taxonomy/accession2taxid/prot.accession2taxid.FULL.gz
wget https://ftp.ncbi.nih.gov/pub/taxonomy/taxdump.tar.gz
tar -xzf taxdump.tar.gz nodes.dmp names.dmp
#+end_src


** Background
detectEVE is based on the EVE search strategy developed by S. Lequime and
previously used in publications ...



